<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Research Areas</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/logo32.png" rel="icon">
  <link href="assets/img/logo180.png" rel="icon">

  <!-- Google Fonts -->
  <link
    href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i"
    rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/icofont/icofont.min.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/venobox/venobox.css" rel="stylesheet">
  <link href="assets/vendor/owl.carousel/assets/owl.carousel.min.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">

  <!--styles -->
  <link href="css/bootstrap.min.css" rel="stylesheet">
  <link href="css/font-awesome.css" rel="stylesheet">
  <link href="js/owl-carousel/owl.carousel.css" rel="stylesheet">
  <link href="js/owl-carousel/owl.theme.css" rel="stylesheet">
  <link href="js/owl-carousel/owl.transitions.css" rel="stylesheet">
  <link href="css/magnific-popup.css" rel="stylesheet">
  <link rel="stylesheet" type="text/css" href="css/animate.css" />
  <link rel="stylesheet" href="css/etlinefont.css">
  <link href="css/style.css" type="text/css" rel="stylesheet" />

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: Scaffold - v2.2.0
  * Template URL: https://bootstrapmade.com/scaffold-bootstrap-metro-style-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->

  <style>
    .collapsible {
      background-color: #0059b3;
      margin-left: 0px;
      color: white;
      cursor: pointer;
      padding: 18px;
      width: 100%;
      border: none;
      text-align: left;
      outline: none;
      font-size: 15px;
    }

    .active,
    .collapsible:hover {
      background-color: #3399ff;
    }

    .collapsible:after {
      content: '\002B';
      color: white;
      font-weight: bold;
      float: right;
      margin-left: 5px;
    }

    .active:after {
      content: "\2212";
    }

    .content {
      padding: 0 18px;
      max-height: 0;
      overflow: hidden;
      transition: max-height 0.2s ease-out;
      background-color: #ecf2f9;
    }
  </style>

</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header" class="fixed-top">
    <div class="container d-flex">
      <img src="assets/img/logo.png" alt="" align="left" width="40px" height="40px">
      <div class="logo mr-auto">
        <h1 class="text-light"><a href="index.html"><span>CSAAT</span></a></h1>
        <!-- Uncomment below if you prefer to use an image logo -->
      </div>

      <nav class="nav-menu d-none d-lg-block">
        <ul>
          <li><a href="index.html">Home</a></li>
          <li><a href="index.html">About Us</a></li>
          <li><a href="index.html">Services</a></li>
          <!--<li><a href="objectives.html">Objectives</a></li>-->
          <li><a href="research-areas.html">Research Areas</a></li>
          <li><a href="publications.html">Publications</a></li>
          <li><a href="team.html">Team</a></li>
          <li><a href="index.html">Contact</a></li>

        </ul>
      </nav><!-- .nav-menu -->

    </div>
  </header><!-- End Header -->

  <main id="main">

    <!-- ======= Breadcrumbs ======= -->
    <section id="breadcrumbs" class="breadcrumbs">
      <div class="container">

        <ol>
          <li><a href="index.html">Home</a></li>
          <li>Research Areas</li>
        </ol>
        <h2>Research Areas</h2>

      </div>
    </section><!-- End Breadcrumbs -->


    <!--Start single-work -->
    <section id="single-work" class="section">
      <div class="container">
        <div class="row">
          <!--
					<div class="col-md-7">						
						<div id="single-work-slider" class="owl-carousel owl-theme">
							<div class="item"><img src="images/works/img4.jpg" alt=""></div>
							<div class="item"><img src="images/works/img5.jpg" alt=""></div>
							<div class="item"><img src="images/works/img6.jpg" alt=""></div>						 
						</div>	
					</div>
					-->

          <!--Start Work Detail-->
          <!--<div class="col-md-5 work-detail"> -->
          <div class="">

            <h3 class="margin-bottom-15" style="color:#24478f; font-size: 23px; font-weight:bolder;">Speech </h3>
            <p style="text-align:justify">Children with ASD often have challenges in speech and language usage. In CSAAT
              project, it is aimed at programming/training a robot to maintain a dialogue with children with the
              intention of recognizing ASD landmarks in the conversation. Robot’s communication interface has speech
              recognition, dialogue management, and speech synthesis to maintain a back-and-forth conversation with
              children. In this research a Sinhala speech synthesizing algorithm must be developed to complete the
              communication interface. </p>

            <br><br>
            <button class="collapsible">Automatic Speech recognition system to screen speech impairments in young
              children to detect ASD</button>
            <div class="content speechREC-research-section" style="max-height: 1601px"><br>
              <p style="text-align:justify">Autism Spectrum Disorder (ASD) is a neuro-developmental disorder
                characterized by social impairments, communication difficulties and repetitive behaviors. Lack of speech
                is the main symptom that 82.4% of children were directed to clinics at the average age of 35.8 months
                and finally get diagnosed for ASD. Children can be directed for early intervention by identifying the
                symptoms appears in speech and language such as difficulties in prosody, abstract use of language,
                echolalia, delay in response and limited amount of functional words that appears as early as first 6 -18
                months of life. Kaldi based novel Automatic Speech Recognition (ASR) system in Sinhala for children is
                to be developed that can recognize speech impairments in autistic children in early childhood utterances
                and help the speech therapists to carryout therapeutic activities to overcome ASD. Moreover, this
                research develops a speech data corpus in Sinhala Language of both typical and atypical children for
                future research.</p><br>
              <p style="text-align:justify;font-weight:bolder;font-size: 20px;">Research Question</p>
              <p style="text-align:justify">How to detect any Sinhala speech and language impairments relative to ASD in
                children?</p>
              <p style="text-align:justify;font-weight:bolder;font-size: 20px; margin-bottom:5px">Sub Research Questions
              </p><br>
              <ul style="color:#3e3e3e; margin-bottom: 10px">
                <li style="margin-bottom: 10px">What are the main speech or language impairments relative to ASD? </li>
                <li style="margin-bottom: 10px">How the Sinhala language or speech of children varies with age?</li>
                <li style="margin-bottom: 10px">What are speech components to analyze to detect any impairments?</li>
                <li style="margin-bottom: 10px">How to detect the speech components and analyze for any impairments?</li>
                <li style="margin-bottom: 10px">How to convert Sinhala speech to text of children?</li>
                <li style="margin-bottom: 10px">How to collect data of typical and atypical children</li>
                <li style="margin-bottom: 10px">How to carry out speech diarization?</li>
              </ul>
              <p style="text-align:justify;font-weight:bolder;font-size: 20px;margin-top:20px">Objective of the study
              </p>
              <p style="text-align:justify">To develop a scanning tool to detect any speech or language impairments
                relative to ASD in children of 12 months to 6 years and develop a Sinhala speech corpus of both typical
                and atypical children for future research</p>
              <p style="text-align:justify;font-weight:bolder;font-size: 20px;"> System Overview Diagram</p>
              <br><br>
              <img style="height:400px; margin: auto; display: block " src="images/speech_rec_sys_diagram.png"
                class="img-fluid" alt="" />
              <br><br>
              <ul class="work-detail-list">
                <li style="font-size: 14px"><span>Area of research :</span>Speech Recognition , Natural Language
                  Processing</li>
                <li style="font-size: 14px"><span>Supervisor :</span>Prof. Koliya Pulasinghe</li>
                <li style="font-size: 14px"><span>Co-supervisor :</span>Dr. Shyam Reyal</li>
                <li style="font-size: 14px"><span>Research Assistant :</span>Ms. Veerandi Kulasekara </li>
                <li style="font-size: 14px"><span>Contact :</span>veerandi.k@sliit.lk</li>
				<li style="font-size: 14px"><span>Current Progress :</span><br>
					✔ Completed MPhil Application <br>
					✔ Completed Interview <br>
					✔ Completed Initial MPhil Presentation <br>
					✔ Next: Comprehensive Presentation <br>
				</li>
              </ul>

              <br><br>
            </div>
            <button class="collapsible">Dialogue Management </button>
            <div class="content dialog-research-section" style="max-height: 1601px"><br>
              <p style="text-align:justify">According to recent statistics, one among 95 kids in Sri Lanka is diagnosed
                with Autism Spectrum Disorder (ASD),
                a neuro-developmental disorder. In Sri Lanka, they are identified at average of 35.6 months of age where
                symptoms can be diagnosed as early as 6 months. Early diagnosis and clinical intervention improve them
                to coexist with typical students when they enter schools. ASD consists of pool of social interaction
                impairments
                including speech and language impairments such as echolalia, poor reciprocity in conversations,
                self-talk, delay
                in response, respond in a few words or no talk at all. A Novel Sinhala Dialogue Management System based
                on
                RASA framework is proposed to engage with atypical kids to instigate above hallmarks in language
                impairments
                to assess the level of impairment and conduct therapeutic conversations to help recovery. Culturally
                inherited
                role-plays and conversational games will be used to sustain interest and engagement of the kids.</p><br>
              <ul class="work-detail-list">
                <li style="font-size: 14px"><span>Area of research :</span>Sinhala Speech Analysis, Dialogue Management,
                  Natural Language Processing</li>
                <li style="font-size: 14px"><span>Supervisor :</span>Prof. Koliya Pulasinghe</li>
                <li style="font-size: 14px"><span>Co-supervisor :</span>Dr. Shyam Reyal</li>
                <li style="font-size: 14px"><span>Research Assistant :</span> </li>
                <li style="font-size: 14px"><span>Contact :</span></li>
              </ul>

              <!-- Adding a picture under  's Research description, 
              change src with correct location, and remove the comment tags. -->


              <!--
            <br><br>
            <img
            style="height:400px; margin: auto; display: block "
            src="images/speech_rec_sys_diagram.png"
            class="img-fluid"
            alt=""
            />
            -->

              <br><br>

            </div>
            <button class="collapsible">Sinhalese Text to Speech with Culturally Sensitive Semantic Information to
              stimulate ASD traits in Children</button>
            <div class="content text2speech-research-section" style="max-height: 1601px"><br>
              <p style="text-align:justify">Autism Spectrum Disorder (ASD) is a neurodevelopment disorder which presents
                a spectrum of symptoms affecting the social interactions of an individual. The challenges faced in
                non-verbal communication and the delays and regression in speech associated with the language
                development of children present the need for an early screening and diagnosis for autistic children,
                allowing them to lead a normal life, with minimal hindrance as a result of their symptoms. The lack of
                diagnostic and screening processes for Autism in Sri Lanka hinders individuals from receiving the
                necessary health care to lead a normal life. This study aims to develop a system to translate Sinhalese
                child directed text to an audio output, with the incorporation of prosodic features to grasp childrens’
                attention. The proposed Text-To-Speech system is the first ever attempt in the development of a speech
                screening tool for children as early as 6 months of age. The analysis in Sinhala language further
                highlights the novelty of this research. The proposed system could be used as a communication interface
                in the attempt of maintaining a smooth back-and-forth conversation between child and robot, to assist in
                the screening of autistic traits in children.</p><br>

              <p style="text-align:justify;font-weight:bolder;font-size: 20px; margin-bottom:5px"> Objectives </p>
              <ul style="color:#3e3e3e; margin-bottom: 15px">
                <li style="margin-bottom: 9px"> Add support for Sinhala language under the MARY environment </li>
                <li style="margin-bottom: 9px"> Develop Sinhalese modules and build a new Sinhalese voice for the Mary
                  TTS system</li>
                <li style="margin-bottom: 9px"> Extensively pre-process the system to synthesize a more natural-sounding
                  intelligible voice</li>
                <li style="margin-bottom: 18px"> Fine-tune TTS system by adjusting features of voice for communication
                  with children, by grasping attention and motivating a child to speak in the hope of stimulating
                  autistic traits through the synthesized voice</li>
              </ul>
              <br><br>

              <p style="text-align:justify;font-weight:bolder;font-size: 20px;">System Overview Diagram</p>
              <br><br>
              <img style="height:600px; margin: auto; display: block " src="images/marytts_architecture.png"
                class="img-fluid" alt="" />
              <br><br>

              <ul class="work-detail-list">
                <li style="font-size: 14px"><span>Area of research :</span>Computer Vision, Machine Learning, Natural
                  Language Processing, Speech Synthesis, Text-To-Speech</li>
                <li style="font-size: 14px"><span>Supervisor :</span>Prof. Koliya Pulasinghe</li>
                <li style="font-size: 14px"><span>Co-supervisor :</span>Dr. Shyam Reyal</li>
                <li style="font-size: 14px"><span>Research Assistant :</span>Ms. Manuri Senarathna</li>
                <li style="font-size: 14px"><span>Contact :</span>manurisenarathna@gmail.com</li>
              </ul> <br><br>


              <!-- Adding a picture under Manuri 's Research description, 
              change src with correct location, and remove the comment tags. -->

              <!--

            <img
            style="height:400px; margin: auto; display: block "
            src="images/speech_rec_sys_diagram.png"
            class="img-fluid"
            alt=""
            />

            -->

              <br><br>

            </div>

            <br><br><br><br><br>
            <div id="gait-research-section"></div>
            <h3 style="color:#24478f; font-size: 23px; font-weight:bolder;" class="margin-bottom-15">computer vision
              based gait and gesture analysis </h3>
            <p style="text-align:justify">A variety of movement disturbances including atypical gait, upper limb
              movements and postural control are also important as early signs of autism. Atypical gait is defined as an
              unusual style of walking from the normal pattern of walking and researchers have tried many different
              variables to test the abnormal gait patterns of children with ASD. Most studies have either used basic
              gait measurements, kinematic, kinetic or a combination of these. A limited research has been conducted on
              the link between infant motor skills and autism and much of the literature tend to provide a qualitative
              description of gait and motion based on the observation of clinicians. Thus, it is imperative to quantify
              these descriptions with measuring tools real time, specially starting as early as 6 months of age.
              Therefore, automated tools for quantitative gait and motion analysis have become vital for assessing
              pathologies manifested by atypical motor behaviors. This research is to analyze the gesture and gait
              patterns of children with Autism. </p>

            <ul class="work-detail-list">
              <li style="font-size: 14px"><span>Area of research :</span>Deep learning , Computer Vision , Digital
                signal processing , robotics , gait and gesture pattern recognition </li>
              <li style="font-size: 14px"><span>Supervisor :</span>Prof. Chandimal Jayawardene (primary), Dr. Pradeepa
                Samarasinghe, Dr. Lasantha Senevirathne</li>
              <li style="font-size: 14px"><span>External Supervisor :</span> Dr. Pratheepan Yogarajah </li>
              <li style="font-size: 14px"><span>Research Assistant :</span>Mr. Gagan hashentha silva</li>
              <li style="font-size: 14px"><span>Contact :</span>gagan.s@sliit.lk</li>
            </ul>



            <!-- Adding a picture under Gagan 's Research description, 
              change src with correct location, and remove the comment tags. -->


            <!--
            <br><br>
            <img
            style="height:400px; margin: auto; display: block "
            src="images/speech_rec_sys_diagram.png"
            class="img-fluid"
            alt=""
            />
            -->


            <br><br><br><br>
            <div id="robot-research-section"></div>
            <h3 style="color:#24478f; font-size: 23px; font-weight:bolder;" class="margin-bottom-15">SOCIALLY ASSISTIVE
              ROBOT AS AN AUTISM EARLY DIAGNOSIS AGENT</h3>
            <p style="text-align:justify">About 1 in every 160 children globally has autism spectrum disorder (ASD). ASD
              is a developmental disability, which is characterized by social, emotional, and communication challenges.
              Recent advancements in the research domain of socially-assistive robots have shown a promising direction
              to use robots to help children with ASD. A socially-assistive robot can be built with capabilities such as
              games to engage children, collect data and to identify the risk of developing ASD; thus, enabling early
              interventions to improve their conditions. Further, recent research has shown that socially-assistive
              robots can be successfully used for enhancing social skills of children with ASD as well. In this
              particular MPhil project an already available programmable robot will be developed as a social-assistive
              robot to perform the above mentioned functions. The primary focus will be on early detection of ASD
              related behavior, although the same robot may be extended as a therapeutic agent as well.</p>

            <ul class="work-detail-list">
              <li style="font-size: 14px"><span>Area of research :</span>Robotics, Machine Learning</li>
              <li style="font-size: 14px"><span>Supervisor :</span>Prof. Koliya Pulasinghe (primary), Prof. Chandimal
                Jayawardena</li>
              <li style="font-size: 14px"><span>External Supervisor :</span></li>
              <li style="font-size: 14px"><span>Research Assistant :</span>Mr. Nadun Ranasinghe</li>
              <li style="font-size: 14px"><span>Contact :</span>nadun.r@sliit.lk</li>
            </ul>

            <!-- Adding a picture under Nadun 's Research description, 
              change src with correct location, and remove the comment tags. -->


            <!--
            <br><br>
            <img
            style="height:400px; margin: auto; display: block "
            src="images/speech_rec_sys_diagram.png"
            class="img-fluid"
            alt=""
            />
            -->

            <br><br><br><br>

            <div id="RRB-research-section"></div>
            <h3 style="color:#24478f; font-size: 23px; font-weight:bolder;" class="margin-bottom-15">Detecting
              Restricted and Repetitive Behaviors </h3>
            <p style="text-align:justify">Once a subject carries out a single action or sticks into a specific sequence actions (Routine type of behaviors) for longer time periods it is known as an RRB.According to key diagnosis journals related to psychological disorders such as Diagnostic and Statistical Manual (DSM), and Classification of Mental and Behavioral Disorders (ICD), globally used by many psychiatrics has stated that Restricted and Repetitive Behaviors (RRB’s) are one of the key features of Autism.Developing a screening tool to detect RRB’s helps to start early interventions, support to overcome the scarcity experties through the automated screening and focusing their service for critical cases,Enables to reach the community who are not aware of autistic symptoms due to varying cultural beliefs, and Helps to achieve the goal of Screen Early, Screen All, and Screen Often. 

</p>
			<p style="text-align:justify;font-weight:bolder;font-size: 20px;">Research Objectives</p>

            <ul style="color:#3e3e3e; margin-bottom: 7px">
              <li style="margin-bottom: 7px">Developing a model to analyze and recognize actions of children.</li>
              <li style="margin-bottom: 7px">Developing a model to detect which actions were repetitive and which were not.</li>
              <li style="margin-bottom: 7px">Developing a model to analyze each repetitive action or multiple repetitive actions conducted by a child with autism.</li>
              <li style="margin-bottom: 7px">Identifying special features such as number of repetitions, duration of each repetition, periodic analysis of the repetitions, aperiodic analysis of the repetitions, unique repetitive actions, motor movement pattern analysis during the repetition through the developed model.
</li>
              <li style="margin-bottom: 7px">Comparing the differences and commonness of repetitive actions, and validating conducted by normal children and children with autism.
</li>
<li style="margin-bottom: 7px">Comparing differences of the repetitive actions conducted by children with autism in different age groups.</li>
<li style="margin-bottom: 7px">Conducting a comparison how cultural variations effects restricted, and repetitive behaviors conducted by children with autism. 
</li>
              </p>
            <p style="text-align:justify;font-weight:bolder;font-size: 20px;">System Overview Diagram</p>
            <br><br>
            <img style="height:500px; margin: auto; display: block " src="images/RRB_Overview_diagram.PNG" class="img-fluid"
              alt="" />

            </ul>
            <ul class="work-detail-list">
              <li style="font-size: 14px"><span>Area of research :</span>Computer Vision, Deep Learning, Signal
                Processsing</li>
              <li style="font-size: 14px"><span>Supervisor :</span>Dr. Pradeepa Samarasinghe (primary), Dr. Lasantha
                Senevirathne</li>
              <li style="font-size: 14px"><span>External Supervisor :</span>Dr. Michela Papandrea, Prof. Alessandro Puiatti,
                Dr. Dulangi Dahanayake, Dr. Swarna Wijethunga</li>
              <li style="font-size: 14px"><span>Research Assistant :</span>Mr. Nushara Wedasingha</li>
              <li style="font-size: 14px"><span>Contact :</span>nushara.w@sliit.lk</li>
            </ul>

            <br><br><br><br>

            <div id="emotion-research-section"></div>
            <h3 style="color:#24478f; font-size: 23px; font-weight:bolder;" class="margin-bottom-15">Facial emotion
              analysis of autistic children</h3>
            <p style="text-align:justify">It has been found that there are significant differences in social interaction
              of children with ASD. Emotion expression and emotion recognition play key roles in social interaction.
              Children with Autism has shown poor emotion expression as well as recognition of others’ emotions. This
              research is aimed at developing an automated tool to identify the deficits in both emotion expression and
              recognition of children with Autism. The automated analysis of smile, imitation of facial expressions,
              responsiveness would signal an early indication of autistic symptoms.</p>
            <p style="text-align:justify;font-weight:bolder;font-size: 20px;">Research Objectives</p>

            <ul style="color:#3e3e3e; margin-bottom: 7px">
              <li style="margin-bottom: 7px">Development of a novel algorithm to predict facial emotion expressions in
                ASD children through videos. </li>
              <li style="margin-bottom: 7px">Analyse existing facial emotion recognition techniques and finetune those
                methodologoies.</li>
              <li style="margin-bottom: 7px">Identify the relationship between valence, arousal and action units towards
                emotion recognition.</li>
              <li style="margin-bottom: 7px">Development of a ensemble based model to predict facial emotions in ASD
                children.</li>
              </p>

            </ul>

            <p style="text-align:justify;font-weight:bolder;font-size: 20px;"> Project Mindmap</p>

            <br><br>
            <img style="height:500px; margin: auto; display: block " src="images/Capture.PNG" class="img-fluid"
              alt="" />
            <ul class="work-detail-list">
              <li style="font-size: 14px"><span>Area of research :</span>Computer Vision, Deep Learning</li>
              <li style="font-size: 14px"><span>Supervisor :</span>Dr. Pradeepa Samarasinghe (primary), Dr. Anuradha
                Karunasena</li>
              <li style="font-size: 14px"><span>External Supervisor :</span></li>
              <li style="font-size: 14px"><span>Research Assistant :</span>Ms. Madhuka Nadeeshani </li>
              <li style="font-size: 14px"><span>Contact :</span>madhuka.n@sliit.lk</li>
            </ul>

            <!-- Adding a picture under Madhuka 's Research description, 
              change src with correct location, and remove the comment tags. -->


            <!--
            <br><br>
            <img
            style="height:400px; margin: auto; display: block "
            src="images/speech_rec_sys_diagram.png"
            class="img-fluid"
            alt=""
            />
            -->

            <br><br><br><br>

            <div id="gaze-research-section"></div>
            <h3 style="color:#24478f; font-size: 23px; font-weight:bolder;" class="margin-bottom-15">Gaze and Attention
              Analysis for the early detection of Autism Spectrum Disorder (ASD)</h3>
            <p style="text-align:justify">Children with ASD have shown variant behaviors in eye contact, disengagement
              of visual attention, visual tracking and social interest and affect in comparison to typically developing
              (TD) children. These social cues that we measure, gaze and attention in particular, can be recorded in
              greater detail and at an early age which would give more opportunities for diagnosis of ASD and early
              intervention. Though there has been few research studies in developed countries using gaze patterns for
              autistic screening, the devices and technologies they have used are not affordable in Sri Lanka. This
              research area attempts to find affordable techniques for evaluating gaze and attention of children with
              Autism. </p>

            <p style="text-align:justify;font-weight:bolder;font-size: 20px;">Research Objectives</p>

            <ul style="color:#3e3e3e; margin-bottom: 7px">
              <li style="margin-bottom: 7px">Development of an algorithm optimized for the reliable estimation of head
                pose of children in a video. </li>
              <li style="margin-bottom: 7px">Development of a model to accurately identify the direction of gaze in
                children, incorporating head pose and eye gaze estimation.</li>
              <li style="margin-bottom: 7px">A comprehensive analysis of gaze and attention for individual tasks which
                trigger atypical traits of in autistic children.</li>
              <li style="margin-bottom: 7px">Development of an ensemble model to screen children for ASD based on their
                patterns of gaze and attention.</li>
              </p>

            </ul>

            <p style="text-align:justify;font-weight:bolder;font-size: 20px;"> Project Mindmap</p>
            <!-- Adding a picture under Vidushani 's Research description, 
              change src with correct location, and remove the comment tags. -->
            <br><br>
            <img style="height:500px; margin: auto; display: block " src="images/MPhil plan Vidushani.png"
              class="img-fluid" alt="" />

            <ul class="work-detail-list">
              <li style="font-size: 14px"><span>Area of research :</span>Computer Vision, Deep Learning</li>
              <li style="font-size: 14px"><span>Supervisor :</span>Dr. Pradeepa Samarasinghe (Primary), Dr. Anuradha
                Karunasena</li>
              <li style="font-size: 14px"><span>External Supervisor :</span>Dr. Bryan Gardiner (Affiliation : Ulster
                University, UK), Dr. Pratheepan Yogarajah (Affiliation : Ulster University, UK)</li>
              <li style="font-size: 14px"><span>Research Assistant :</span>Ms. Vidushani Dhanawansa </li>
              <li style="font-size: 14px"><span>Contact :</span>vidushani.d@sliit.lk</li>
            </ul>

            <br><br><br><br>

            <div id="provenace-research-section"></div>
            <h3 style="color:#24478f; font-size: 23px; font-weight:bolder;" class="margin-bottom-15">Provenance
              Preserving Scientific Data Store for Research Data</h3>
            <p style="text-align:justify">The CSAAT project aims to early-detect Autism in young children using
              anomalies in emotion, gaze, movement, and speech by application of machine learning / deep learning
              techniques. This requires collection and storage of large volumes of video, speech and image data, along
              with corresponding meta-data. Meta-data could be automatically extracted features from the data, or
              annotations made by researchers. Further, it is required to perform custom queries to retrieve certain
              subsets of this data on-demand, using the above meta-data as search parameters. This section addresses the
              research questions such as what meta-data could (and should) be extracted from the source data, how best
              to design the interface to make annotations, and how the meta-data could be stored and indexed.</p>

            <ul class="work-detail-list">
              <li style="font-size: 14px"><span>Area of research :</span>Computer Vision, Deep Learning</li>
              <li style="font-size: 14px"><span>Supervisor :</span>Dr. Shyam Reyal (primary), Dr. Pradeepa Samarasinghe,
                Dr. Anuradha Karunasena</li>
              <li style="font-size: 14px"><span>Research Assistant :</span> </li>
              <li style="font-size: 14px"><span>Contact :</span></li>
            </ul>

            <!-- Adding a picture under  's Research description, 
              change src with correct location, and remove the comment tags. -->


            <!--
            <br><br>
            <img
            style="height:400px; margin: auto; display: block "
            src="images/speech_rec_sys_diagram.png"
            class="img-fluid"
            alt=""
            />
            -->

            <br><br><br><br>
            <div id="federated-research-section"></div>
            <h3 style="color:#24478f; font-size: 23px; font-weight:bolder;" class="margin-bottom-15">Federated Learning
              Models for Distributed Mobile Computing</h3>
            <p style="text-align:justify">The CSAAT project aims to early-detect Autism in young children using
              anomalies in emotion, gaze, movement, and speech by application of machine learning / deep learning
              techniques. The major objective of this study is to build a mobile app capable of handling various machine
              learning algorithms optimised for the mobile environment in the most suitable way according to the
              available resources of the device and network capabilities. The ultimate goal of this section is to
              implement a mobile-app for the general public which concerned parties (parents, carers, etc.) that can be
              used to upload a video, voice-clip, or image of a child onto the the mobile app for preliminary screening
              for Autism in multiple ways powered by AI based recognition systems implemented by the CSAAT project team.
              This section focuses on the mobile application endpoint of the CSAAT project.</p>
            <p style="text-align:justify;font-weight:bolder;font-size: 20px;">Research Questions</p>
            <p style="text-align:justify">Given the usage of a model and a specific edge device can it be deployed on
              edge device itself or will it has to be deployed on a cloud service in order to get the expcected
              prediction or output?</p>
            <p style="text-align:justify;font-weight:bolder;font-size: 16px; margin-bottom:5px">Sub Research Questions
            </p>
            <ul style="color:#3e3e3e; margin-bottom: 7px">
              <li style="margin-bottom: 7px">How benchmarking works and what are the parameters tested by benchmark
                tests?</li>
              <li style="margin-bottom: 7px">What is indicated by the result of a benchmarks test regarding capability
                of mobile ?</li>
              <li style="margin-bottom: 7px">How the benchmarks tests can be compared with each other?</li>
              <li style="margin-bottom: 7px">How to use benchmarking in order to decide if a particular model can be
                deployed on a mobile or not? </li>
              <li style="margin-bottom: 7px">Can an existing neural network be optimized using optimizing techniques and
                convert to a mobile friendly architecture?</li>
              <li style="margin-bottom: 7px">Given the use case of a neural network what is the best way to optimize it
                for the mobile environment?</li>
              <li style="margin-bottom: 7px">What are the available cloud services to deploy machine learning models and
                what are their capabilities, limitations, pros and cons?</li>
              <li style="margin-bottom: 7px">What is the best way to run deep learning model predictions in mobile app?
              </li>
            </ul>
            <p style="text-align:justify;font-weight:bolder;font-size: 20px;margin-top:20px">Objective of the study</p>
            <p style="text-align:justify">The major objective of this study is to build a mobile app capable of handling
              various machine learning algorithms optimized for the mobile environment in the best way according to the
              available resources of the device and network capabilities. </p>
            <p style="text-align:justify;font-weight:bolder;font-size: 20px;">Project Mindmap</p>
            <br><br>
            <img style="height:700px; margin: auto; display: block " src="images/federated_mindmap.png"
              class="img-fluid" alt="" />
            <br><br>
            <ul class="work-detail-list">
              <li style="font-size: 14px"><span>Area of research :</span>Network Optimization and Acceleration, Mobile
                Computing, Distributed Computing, Machine Learning, Federated Learning</li>
              <li style="font-size: 14px"><span>Supervisor :</span>Dr. Nuwan Kodagoda (primary), Dr. Dharshana
                Kasthurirathna, Dr. Shyam Reyal, Dr. Pradeepa Samarasinghe</li>
              <li style="font-size: 14px"><span>Research Assistant :</span>Mr. Asiri Gawesha Lindamulage </li>
              <li style="font-size: 14px"><span>Contact :</span>asiri.l@sliit.lk</li>
            </ul>


            <br><br><br><br>
            <div id="graphNN-research-section"></div>

            <!--<h3 style="color:#24478f; font-size: 23px; font-weight:bolder;" class="margin-bottom-15">Joint Attention
              Analysis</h3>
            <p style="text-align:justify">The main analysis on the CSAAT project involves videos of children for early
              detection of the
              autism spectrum disorder (ASD). Often, monitoring and quantifying the ability of children to interact with
              parents and professional therapists is essential in identifying any potential issues in their development
              growth. In this research, we plan to analyse the interactions between child and mother/examiner. This
              involves the use of image pre-processing techniques along with deep learning techniques such as graph
              neural networks to analyse the behaviours of the child as well as his/her interaction with others. The
              outcomes of this research may be useful in early identification and continuous monitoring of development
              goals and social interaction expectations of children.</p>

            <ul class="work-detail-list">
              <li style="font-size: 14px"><span>Area of research :</span>Deep Learning, Computer Vision</li>
              <li style="font-size: 14px"><span>Supervisor :</span>Dr. Pradeepa Samarasinghe (primary), Dr. Dharshana
                Kasthurirathna</li>
              <li style="font-size: 14px"><span>External Supervisor :</span>Dr. Charith Abhayaratne</li>
              -->
             
						<h3 style="color:#24478f; font-size: 23px; font-weight:bolder;" class="margin-bottom-15">Joint Attention Analysis</h3>	
						<p style="text-align:justify">The main analysis on the CSAAT project involves videos of children for early detection of the
autism spectrum disorder (ASD). Often, monitoring and quantifying the ability of children to interact with parents and professional therapists is essential in identifying any potential issues in their development growth. In this research, we plan to analyse the interactions between child and mother/examiner. This involves the use of image pre-processing techniques along with deep learning techniques such as graph neural networks to analyse the behaviours of the child as well as his/her interaction with others. The outcomes of this research may be useful in early identification and continuous monitoring of development goals and social interaction expectations of children.</p>					
						 <p style="text-align:justify;font-weight:bolder;font-size: 20px;">Research Objectives</p>
						  
							 <ul style="color:#3e3e3e; margin-bottom: 7px" >
								<li style="margin-bottom: 7px">Doing a comprehensive literature review of human - human interaction recognitions systems curently developed with an emphasise on deep learning methods. </li>
								<li style="margin-bottom: 7px">Analysing available child action/behavior datasets and looking into the possiblity of developing a dataset.</li>
								<li style="margin-bottom: 7px">Developing a robust action recognition graph neural network (GNN) based model for detecting child actions/behaviors.</li>
								<li style="margin-bottom: 7px">Doing a comprehensive literature review of graph neural network achitectures which can be utilized in this research.</li>
                <li style="margin-bottom: 7px">Developing a GNN based adult-child interaction recognition model in order to assess joint attention of a child.</li></p>
							</ul>  

						<ul class="work-detail-list">
							<li style="font-size: 14px"><span>Area of research :</span>Deep Learning, Computer Vision</li>
							<li style="font-size: 14px"><span>Supervisor :</span>Dr. Pradeepa Samarasinghe (primary), Dr. Dharshana Kasthurirathna</li>
							<li style="font-size: 14px"><span>External Supervisor :</span>Dr. Charith Abhayaratne</li>

              <li style="font-size: 14px"><span>Research Assistant :</span>Mr. Sanka Mohottala </li>
              <li style="font-size: 14px"><span>Contact :</span>sanka.m@sliit.lk</li>
            </ul>

            <!-- Adding a picture under  Sanka 's Research description, 
              change src with correct location, and remove the comment tags. -->


            <!--
            <br><br>
            <img
            style="height:400px; margin: auto; display: block "
            src="images/speech_rec_sys_diagram.png"
            class="img-fluid"
            alt=""
            />
            -->

          </div>
          <!--End Work Detail-->
        </div>
        <!--/ row-->
      </div>
      <!--/ container-->
    </section>
    <!--End single-work -->

    <!-- MPhil Progress-->
    <section>

      <canvas id="horizontalBar"></canvas>
    </section>

    <script>
      var coll = document.getElementsByClassName("collapsible");
      var i;

      for (i = 0; i < coll.length; i++) {
        coll[i].addEventListener("click", function () {
          this.classList.toggle("active");
          var content = this.nextElementSibling;
          if (content.style.maxHeight) {
            content.style.maxHeight = null;
          } else {
            content.style.maxHeight = content.scrollHeight + "px";
          }
        });
      }
    </script>

<script>
  new Chart(document.getElementById("horizontalBar"), {
    "type": "horizontalBar",
    "data": {
      "labels": ["Red", "Orange", "Yellow", "Green", "Blue", "Purple", "Grey"],
      "datasets": [{
        "label": "My First Dataset",
        "data": [22, 33, 55, 12, 86, 23, 14],
        "fill": false,
        "backgroundColor": ["rgba(255, 99, 132, 0.2)", "rgba(255, 159, 64, 0.2)",
          "rgba(255, 205, 86, 0.2)", "rgba(75, 192, 192, 0.2)", "rgba(54, 162, 235, 0.2)",
          "rgba(153, 102, 255, 0.2)", "rgba(201, 203, 207, 0.2)"
        ],
        "borderColor": ["rgb(255, 99, 132)", "rgb(255, 159, 64)", "rgb(255, 205, 86)",
          "rgb(75, 192, 192)", "rgb(54, 162, 235)", "rgb(153, 102, 255)", "rgb(201, 203, 207)"
        ],
        "borderWidth": 1
      }]
    },
    "options": {
      "scales": {
        "xAxes": [{
          "ticks": {
            "beginAtZero": true
          }
        }]
      }
    }
  });
</script>

    </section>

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer id="footer">

    <div class="container">
      <div class="copyright">
        &copy; Copyright <strong><span>CSAAT</span></strong>. All Rights Reserved
      </div>
      <div class="credits">
        <!-- All the links in the footer should remain intact. -->
        <!-- You can delete the links only if you purchased the pro version. -->
        <!-- Licensing information: https://bootstrapmade.com/license/ -->
        <!-- Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/scaffold-bootstrap-metro-style-template/ -->
        Designed by <a href="https://www.sliit.lk/">SLIIT</a>
      </div>
    </div>
  </footer><!-- End Footer -->

  <a href="#" class="back-to-top"><i class="bx bxs-up-arrow-alt"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/jquery/jquery.min.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/jquery.easing/jquery.easing.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/venobox/venobox.min.js"></script>
  <script src="assets/vendor/owl.carousel/owl.carousel.min.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

 
</body>

</html>