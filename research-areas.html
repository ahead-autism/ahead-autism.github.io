<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Research Areas</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/logo32.png" rel="logo32">
  <link href="assets/img/logo180.png" rel="logo180">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/icofont/icofont.min.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/venobox/venobox.css" rel="stylesheet">
  <link href="assets/vendor/owl.carousel/assets/owl.carousel.min.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  
   <!--styles -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/font-awesome.css" rel="stylesheet">
    <link href="js/owl-carousel/owl.carousel.css" rel="stylesheet">
    <link href="js/owl-carousel/owl.theme.css" rel="stylesheet">
    <link href="js/owl-carousel/owl.transitions.css" rel="stylesheet">
    <link href="css/magnific-popup.css" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="css/animate.css" />
    <link rel="stylesheet" href="css/etlinefont.css">
    <link href="css/style.css" type="text/css"  rel="stylesheet"/>

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: Scaffold - v2.2.0
  * Template URL: https://bootstrapmade.com/scaffold-bootstrap-metro-style-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
  
  <style>
.collapsible {
  background-color: #0059b3;
  margin-left:0px;
  color: white;
  cursor: pointer;
  padding: 18px;
  width: 100%;
  border: none;
  text-align: left;
  outline: none;
  font-size: 15px;
}

.active, .collapsible:hover {
  background-color: #3399ff;
}

.collapsible:after {
  content: '\002B';
  color: white;
  font-weight: bold;
  float: right;
  margin-left: 5px;
}

.active:after {
  content: "\2212";
}

.content {
  padding: 0 18px;
  max-height: 0;
  overflow: hidden;
  transition: max-height 0.2s ease-out;
  background-color: #ecf2f9;
}

</style>

</head>

<body>

   <!-- ======= Header ======= -->
  <header id="header" class="fixed-top">
    <div class="container d-flex">
      <img src="assets/img/logo.png" alt="" align="left" width="40px" height="40px">
      <div class="logo mr-auto">
        <h1 class="text-light"><a href="index.html"><span>CSAAT</span></a></h1>
        <!-- Uncomment below if you prefer to use an image logo -->
      </div>

      <nav class="nav-menu d-none d-lg-block">
        <ul>
          <li><a href="index.html">Home</a></li>
		  <li><a href="index.html">About Us</a></li>
          <li><a href="index.html">Services</a></li>
          <!--<li><a href="objectives.html">Objectives</a></li>-->
          <li><a href="research-areas.html">Research Areas</a></li>
          <li><a href="team.html">Team</a></li>
          <li><a href="index.html">Contact</a></li>

        </ul>
      </nav><!-- .nav-menu -->

    </div>
  </header><!-- End Header -->

  <main id="main">

    <!-- ======= Breadcrumbs ======= -->
    <section id="breadcrumbs" class="breadcrumbs">
      <div class="container">

        <ol>
          <li><a href="index.html">Home</a></li>
          <li>Research Areas</li>
        </ol>
        <h2>Research Areas</h2>

      </div>
    </section><!-- End Breadcrumbs -->

	  
	  <!--Start single-work -->
		<section id="single-work" class="section">
			<div class="container">
				<div class="row">	
					<!--
					<div class="col-md-7">						
						<div id="single-work-slider" class="owl-carousel owl-theme">
							<div class="item"><img src="images/works/img4.jpg" alt=""></div>
							<div class="item"><img src="images/works/img5.jpg" alt=""></div>
							<div class="item"><img src="images/works/img6.jpg" alt=""></div>						 
						</div>	
					</div>
					-->
                    
                    <!--Start Work Detail-->
					<!--<div class="col-md-5 work-detail"> -->
					<div class="">
					
                        <h3 class="margin-bottom-15" style="color:#24478f; font-size: 23px; font-weight:bolder;">Speech </h3>
						<p style="text-align:justify">Children with ASD often have challenges in speech and language usage. In CSAAT project, it is aimed at programming/training a robot to maintain a dialogue with children with the intention of recognizing ASD landmarks in the conversation. Robot’s communication interface has speech recognition, dialogue management, and speech synthesis to maintain a back-and-forth conversation with children. In this research a Sinhala speech synthesizing algorithm must be developed to complete the communication interface.  </p>

						<br><br>
						<button class="collapsible">Automatic Speech recognition system to screen speech impairments  in young children to detect ASD</button>
						<div class="content speechREC-research-section"><br>
						  <p style="text-align:justify">Autism Spectrum Disorder (ASD) is a neuro-developmental disorder characterized by social impairments, communication difficulties and repetitive behaviors. Lack of speech is the main symptom that 82.4% of children were directed to clinics at the average age of 35.8 months and finally get diagnosed for ASD. Children can be directed for early intervention by identifying the symptoms appears in speech and language such as difficulties in prosody, abstract use of language, echolalia, delay in response and limited amount of functional words that appears as early as first 6 -18 months of life. Kaldi based novel Automatic Speech Recognition (ASR) system in Sinhala for children is to be developed that can recognize speech impairments in autistic children in early childhood utterances and help the speech therapists to carryout therapeutic activities to overcome ASD. Moreover, this research develops a speech data corpus in Sinhala Language of both typical and atypical children for future research.</p><br>
						<p style="text-align:justify;font-weight:bolder;font-size: 20px;">Research Questions</p>
						<p style="text-align:justify">How to detect any Sinhala speech and language impairments relative to ASD in children?</p>				
						<p style="text-align:justify;font-weight:bolder;font-size: 16px; margin-bottom:5px">Sub Research Questions</p>
						<ul style="color:#3e3e3e; margin-bottom: 7px" >
						<li style="margin-bottom: 7px">What are the main speech or language impairments relative to ASD? </li>
						<li style="margin-bottom: 7px">How the Sinhala language or speech of children varies with age?</li>
						<li style="margin-bottom: 7px">What are speech components to analyze to detect any impairments?</li>
						<li style="margin-bottom: 7px">How to detect the speech components and analyze for any impairments?</li>
						<li style="margin-bottom: 7px">How to convert Sinhala speech to text of children?</li>
						<li style="margin-bottom: 7px">How to collect data of typical and atypical children</li>
						<li style="margin-bottom: 7px">How to carry out speech diarization?</li>
					</ul>            
						<p style="text-align:justify;font-weight:bolder;font-size: 20px;margin-top:20px">Objective of the study</p>					
						<p style="text-align:justify">To develop a scanning tool to detect any speech or language impairments relative to ASD in children of 12 months to 6 years and develop a Sinhala speech corpus of both typical and atypical children for future research</p>	
						<p style="text-align:justify;font-weight:bolder;font-size: 20px;"> Project System Diagram</p>	 
					<br><br>		
			<img
            style="height:400px; margin: auto; display: block "
            src="images/speech_rec_sys_diagram.png"
            class="img-fluid"
            alt=""
            />
			<br><br>			
							<ul class="work-detail-list">
							<li style="font-size: 14px"><span>Area of research :</span>Speech Recognition , Natural Language Processing</li>
							<li style="font-size: 14px"><span>Supervisor :</span>Prof. Koliya Pulasinghe</li>
                            <li style="font-size: 14px"><span>Co-supervisor :</span>Dr. Shyam Reyal</li>
							<li style="font-size: 14px"><span>Research Assistant :</span>Ms. Veerandi Kulasekara </li>
              <li style="font-size: 14px"><span>Contact :</span>veerandi.k@sliit.lk</li>
						</ul> 
            
            <br><br>
						</div>
						<button class="collapsible">Dialogue Management </button>
						<div class="content dialog-research-section"><br>
						  <p style="text-align:justify">According to recent statistics, one among 95 kids in Sri Lanka is diagnosed with Autism Spectrum Disorder (ASD),
a neuro-developmental disorder. In Sri Lanka, they are identified at average of 35.6 months of age where
symptoms can be diagnosed as early as 6 months. Early diagnosis and clinical intervention improve them to coexist with typical students when they enter schools. ASD consists of pool of social interaction impairments
including speech and language impairments such as echolalia, poor reciprocity in conversations, self-talk, delay
in response, respond in a few words or no talk at all. A Novel Sinhala Dialogue Management System based on
RASA framework is proposed to engage with atypical kids to instigate above hallmarks in language impairments
to assess the level of impairment and conduct therapeutic conversations to help recovery. Culturally inherited
role-plays and conversational games will be used to sustain interest and engagement of the kids.</p><br>
						<ul class="work-detail-list">
							<li style="font-size: 14px"><span>Area of research :</span>Sinhala Speech Analysis, Dialogue Management, Natural Language Processing</li>
							<li style="font-size: 14px"><span>Supervisor :</span>Prof. Koliya Pulasinghe</li>
                            <li style="font-size: 14px"><span>Co-supervisor :</span>Dr. Shyam Reyal</li>
							<li style="font-size: 14px"><span>Research Assistant :</span> </li>
              <li style="font-size: 14px"><span>Contact :</span></li>
						</ul> 
            
              <!-- Adding a picture under  's Research description, 
              change src with correct location, and remove the comment tags. -->

           
            <!--
            <br><br>
            <img
            style="height:400px; margin: auto; display: block "
            src="images/speech_rec_sys_diagram.png"
            class="img-fluid"
            alt=""
            />
            -->
            
            <br><br>
						
						</div>
						<button class="collapsible">Sinhalese Text to Speech with Culturally Sensitive Semantic Information to stimulate ASD traits in Children</button>
						<div class="content text2speech-research-section" ><br>  
						  <p style="text-align:justify">Autism Spectrum Disorder (ASD) is a neurodevelopment disorder which presents a spectrum of symptoms affecting the social interactions of an individual. The challenges faced in non-verbal communication and the delays and regression in speech associated with the language development of children present the need for an early screening and diagnosis for autistic children, allowing them to lead a normal life, with minimal hindrance as a result of their symptoms. The lack of diagnostic and screening processes for Autism in Sri Lanka hinders individuals from receiving the necessary health care to lead a normal life. This study aims to develop a system to translate Sinhalese child directed text to an audio output, with the incorporation of prosodic features to grasp childrens’ attention. The proposed Text-To-Speech system is the first ever attempt in the development of a speech screening tool for children as early as 6 months of age. The analysis in Sinhala language further highlights the novelty of this research. The proposed system could be used as a communication interface in the attempt of maintaining a smooth back-and-forth conversation between child and robot, to assist in the screening of autistic traits in children.</p><br>

            <p style="text-align:justify;font-weight:bolder;font-size: 20px; margin-bottom:5px"> Objectives </p>
            <ul style="color:#3e3e3e; margin-bottom: 15px" >
            <li style="margin-bottom: 9px"> Add support for Sinhala language under the MARY environment </li>
            <li style="margin-bottom: 9px"> Develop Sinhalese modules and build a new Sinhalese voice for the Mary TTS system</li>
            <li style="margin-bottom: 9px"> Extensively pre-process the system to synthesize a more natural-sounding intelligible voice</li>
            <li style="margin-bottom: 9px"> Fine-tune TTS system by adjusting features of voice for communication with children, by grasping attention and motivating a child to speak in the hope of stimulating autistic traits through the synthesized voice</li>
          </ul>  
          <br><br>

              <p style="text-align:justify;font-weight:bolder;font-size: 20px;"> System Overview</p>  
          <br><br>    
      <img
            style="height:600px; margin: auto; display: block "
            src="images/marytts_architecture.png"
            class="img-fluid"
            alt=""
            />
            <br><br>
  
						<ul class="work-detail-list">
							<li style="font-size: 14px"><span>Area of research :</span>Computer Vision, Machine Learning, Natural Language Processing, Speech Synthesis, Text-To-Speech</li>
							<li style="font-size: 14px"><span>Supervisor :</span>Prof. Koliya Pulasinghe</li>
                            <li style="font-size: 14px"><span>Co-supervisor :</span>Dr. Shyam Reyal</li>
							<li style="font-size: 14px"><span>Research Assistant :</span>Ms. Manuri Senarathna</li>
              <li style="font-size: 14px"><span>Contact :</span>manurisenarathna@gmail.com</li>
						</ul> <br><br>
						
        
            <!-- Adding a picture under Manuri 's Research description, 
              change src with correct location, and remove the comment tags. -->

            <!--

            <img
            style="height:400px; margin: auto; display: block "
            src="images/speech_rec_sys_diagram.png"
            class="img-fluid"
            alt=""
            />

            -->

            <br><br>

						</div>
						
						<br><br><br><br><br>
            <div id="gait-research-section"></div>
						<h3 style="color:#24478f; font-size: 23px; font-weight:bolder;" class="margin-bottom-15">computer vision based gait and gesture analysis </h3>	
						<p style="text-align:justify">A variety of movement disturbances including atypical gait, upper limb movements and postural control are also important as early signs of autism. Atypical gait is defined as an unusual style of walking from the normal pattern of walking and researchers have tried many different variables to test the abnormal gait patterns of children with ASD. Most studies have either used basic gait measurements, kinematic, kinetic or a combination of these. A limited research has been conducted on the link between infant motor skills and autism and much of the literature tend to provide a qualitative description of gait and motion based on the observation of clinicians. Thus, it is imperative to quantify these descriptions with measuring tools real time, specially starting as early as 6 months of age. Therefore, automated tools for quantitative gait and motion analysis have become vital for assessing pathologies manifested by atypical motor behaviors. This research is to analyze the gesture and gait patterns of children with Autism. </p>					
						 
						<ul class="work-detail-list">
							<li style="font-size: 14px"><span>Area of research :</span>Deep learning , Computer Vision , Digital signal processing , robotics , gait and gesture pattern recognition </li>
							<li style="font-size: 14px"><span>Supervisor :</span>Prof. Chandimal Jayawardene (primary), Dr. Pradeepa Samarasinghe, Dr. Lasantha Senevirathne</li>
                            <li style="font-size: 14px"><span>External Supervisor :</span> Dr. Pratheepan Yogarajah </li>
							<li style="font-size: 14px"><span>Research Assistant :</span>Mr. Gagan hashentha silva</li>
              <li style="font-size: 14px"><span>Contact :</span>gagan.s@sliit.lk</li>
						</ul>
						
						

              <!-- Adding a picture under Gagan 's Research description, 
              change src with correct location, and remove the comment tags. -->

           
            <!--
            <br><br>
            <img
            style="height:400px; margin: auto; display: block "
            src="images/speech_rec_sys_diagram.png"
            class="img-fluid"
            alt=""
            />
            -->
           
            
            <br><br><br><br>
            <div id="robot-research-section"></div>
						<h3 style="color:#24478f; font-size: 23px; font-weight:bolder;" class="margin-bottom-15">SOCIALLY ASSISTIVE ROBOT AS AN AUTISM EARLY DIAGNOSIS AGENT</h3>	
						<p style="text-align:justify">About 1 in every 160 children globally has autism spectrum disorder (ASD). ASD is a developmental disability, which is characterized by social, emotional, and communication challenges. Recent advancements in the research domain of socially-assistive robots have shown a promising direction to use robots to help children with ASD. A socially-assistive robot can be built with capabilities such as games to engage children, collect data and to identify the risk of developing ASD; thus, enabling early interventions to improve their conditions. Further, recent research has shown that socially-assistive robots can be successfully used for enhancing social skills of children with ASD as well. In this particular MPhil project an already available programmable robot will be developed as a social-assistive robot to perform the above mentioned functions. The primary focus will be on early detection of ASD related behavior, although the same robot may be extended as a therapeutic agent as well.</p>					
						 
						<ul class="work-detail-list">
							<li style="font-size: 14px"><span>Area of research :</span>Robotics, Machine Learning</li>
							<li style="font-size: 14px"><span>Supervisor :</span>Prof. Koliya Pulasinghe (primary), Prof. Chandimal Jayawardena</li>
                            <li style="font-size: 14px"><span>External Supervisor :</span></li>
							<li style="font-size: 14px"><span>Research Assistant :</span>Mr. Nadun Ranasinghe</li>
              <li style="font-size: 14px"><span>Contact :</span>nadun.r@sliit.lk</li>
						</ul>

              <!-- Adding a picture under Nadun 's Research description, 
              change src with correct location, and remove the comment tags. -->

           
            <!--
            <br><br>
            <img
            style="height:400px; margin: auto; display: block "
            src="images/speech_rec_sys_diagram.png"
            class="img-fluid"
            alt=""
            />
            -->
						
						<br><br><br><br>

            <div id="RRB-research-section"></div>
						<h3 style="color:#24478f; font-size: 23px; font-weight:bolder;" class="margin-bottom-15">Detecting Restricted and Repetitive Behaviors </h3>	
						<p style="text-align:justify">The presence of restrictive and repetitive behaviors (RRBs), interests, and activities is one of the key indicators of Autism. Individuals may engage in stereotyped and repetitive motor movements (e.g., hand flapping, rocking, punching, drumming or lining up items) or speech. They may have an insistence on sameness. RRBs can be problematic when others interfere with the child’s way of behavior leading to anxiety and aggression. This research focuses on identifying the RRBs of the children and finding ways to automate the behavior analysis and prediction.</p>					
						 
						<ul class="work-detail-list">
							<li style="font-size: 14px"><span>Area of research :</span>Computer Vision, Deep Learning, Signal Processsing</li>
							<li style="font-size: 14px"><span>Supervisor :</span>Dr. Pradeepa Samarasinghe (primary), Dr. Lasantha Senevirathne</li>
                            <li style="font-size: 14px"><span>External Supervisor :</span>Michela Papandrea, Prof. Alessandro Puiatti, Dr. Dulangi Dahanayake, Dr. Swarna Wijethunga</li>
							<li style="font-size: 14px"><span>Research Assistant :</span>Mr. Nushara Wedasinghe</li>
              <li style="font-size: 14px"><span>Contact :</span>nushara.w@sliit.lk</li>
						</ul>

              <!-- Adding a picture under Nushara 's Research description, 
              change src with correct location, and remove the comment tags. -->

           
            <!--
            <br><br>
            <img
            style="height:400px; margin: auto; display: block "
            src="images/speech_rec_sys_diagram.png"
            class="img-fluid"
            alt=""
            />
            -->
						
						<br><br><br><br>

            <div id="emotion-research-section"></div>
						<h3 style="color:#24478f; font-size: 23px; font-weight:bolder;" class="margin-bottom-15">Facial emotion analysis of autistic children</h3>	
						<p style="text-align:justify">It has been found that there are significant differences in social interaction of children with ASD. Emotion expression and emotion recognition play key roles in social interaction. Children with Autism has shown poor emotion expression as well as recognition of others’ emotions. This research is aimed at developing an automated tool to identify the deficits in both emotion expression and recognition of children with Autism. The automated analysis of smile, imitation of facial expressions, responsiveness would signal an early indication of autistic symptoms.</p>					
						 
						<ul class="work-detail-list">
							<li style="font-size: 14px"><span>Area of research :</span>Computer Vision, Deep Learning</li>
							<li style="font-size: 14px"><span>Supervisor :</span>Dr. Pradeepa Samarasinghe (primary), Dr. Anuradha Karunasena</li>
                            <li style="font-size: 14px"><span>External Supervisor :</span></li>
							<li style="font-size: 14px"><span>Research Assistant :</span>Ms. Madhuka Nadeeshani </li>
              <li style="font-size: 14px"><span>Contact :</span>madhuka.n@sliit.lk</li>
						</ul>

              <!-- Adding a picture under Madhuka 's Research description, 
              change src with correct location, and remove the comment tags. -->

           
            <!--
            <br><br>
            <img
            style="height:400px; margin: auto; display: block "
            src="images/speech_rec_sys_diagram.png"
            class="img-fluid"
            alt=""
            />
            -->
						
						<br><br><br><br>

            <div id="gaze-research-section"></div>
						<h3 style="color:#24478f; font-size: 23px; font-weight:bolder;" class="margin-bottom-15">Gaze and Attention Analysis for the early detection of Autism Spectrum Disorder (ASD)</h3>	
						<p style="text-align:justify">Children with ASD have shown variant behaviors in eye contact, disengagement of visual attention, visual tracking and social interest and affect in comparison to typically developing (TD) children. These social cues that we measure, gaze and attention in particular, can be recorded in greater detail and at an early age which would give more opportunities for diagnosis of ASD and early intervention. Though there has been few research studies in developed countries using gaze patterns for autistic screening, the devices and technologies they have used are not affordable in Sri Lanka. This research area attempts to find affordable techniques for evaluating gaze and attention of children with Autism. </p>					
						 
						<ul class="work-detail-list">
							<li style="font-size: 14px"><span>Area of research :</span>Computer Vision, Deep Learning</li>
							<li style="font-size: 14px"><span>Supervisor :</span>Dr. Pradeepa Samarasinghe (primary), Dr. Anuradha Karunasena</li>
                            <li style="font-size: 14px"><span>External Supervisor :</span>Dr. Bryan Gardiner</li>
							<li style="font-size: 14px"><span>Research Assistant :</span>Ms. Vidushani Dhanawansa </li>
              <li style="font-size: 14px"><span>Contact :</span>vidushani.d@sliit.lk</li>
						</ul>
						
              <!-- Adding a picture under Vidushani 's Research description, 
              change src with correct location, and remove the comment tags. -->

            
            <!--
            <br><br>
            <img
            style="height:400px; margin: auto; display: block "
            src="images/speech_rec_sys_diagram.png"
            class="img-fluid"
            alt=""
            />
            --> 
            <br><br><br><br>
            
            <div id="provenace-research-section"></div>
						<h3 style="color:#24478f; font-size: 23px; font-weight:bolder;" class="margin-bottom-15">Provenance Preserving Scientific Data Store for Research Data</h3>	
						<p style="text-align:justify">The CSAAT project aims to early-detect Autism in young children using anomalies in emotion, gaze, movement, and speech by application of machine learning / deep learning techniques. This requires collection and storage of large volumes of video, speech and image data, along with corresponding meta-data. Meta-data could be automatically extracted features from the data, or annotations made by researchers. Further, it is required to perform custom queries to retrieve certain subsets of this data on-demand, using the above meta-data as search parameters. This section addresses the research questions such as what meta-data could (and should) be extracted from the source data, how best to design the interface to make annotations, and how the meta-data could be stored and indexed.</p>					
						 
						<ul class="work-detail-list">
							<li style="font-size: 14px"><span>Area of research :</span>Computer Vision, Deep Learning</li>
							<li style="font-size: 14px"><span>Supervisor :</span>Dr. Shyam Reyal (primary), Dr. Pradeepa Samarasinghe, Dr. Anuradha Karunasena</li>
							<li style="font-size: 14px"><span>Research Assistant :</span> </li>
              <li style="font-size: 14px"><span>Contact :</span></li>
						</ul>

              <!-- Adding a picture under  's Research description, 
              change src with correct location, and remove the comment tags. -->

           
            <!--
            <br><br>
            <img
            style="height:400px; margin: auto; display: block "
            src="images/speech_rec_sys_diagram.png"
            class="img-fluid"
            alt=""
            />
            -->
						
						<br><br><br><br>
            <div id="federated-research-section"></div>
						<h3 style="color:#24478f; font-size: 23px; font-weight:bolder;" class="margin-bottom-15">Federated Learning Models for Distributed Mobile Computing</h3>	
						<p style="text-align:justify">The CSAAT project aims to early-detect Autism in young children using anomalies in emotion, gaze, movement, and speech by application of machine learning / deep learning techniques. The major objective of this study is to build a mobile app capable of handling various machine learning algorithms optimised for the mobile environment in the most suitable way according to the available resources of the device and network capabilities.  The ultimate goal of this section is to implement a mobile-app for the general public which concerned parties (parents, carers, etc.) that can be used to upload a video, voice-clip, or image of a child onto the the mobile app for preliminary screening for Autism in multiple ways powered by AI based recognition systems implemented by the CSAAT project team. This section focuses on the mobile application endpoint of the CSAAT project.</p>					
						<p style="text-align:justify;font-weight:bolder;font-size: 20px;">Research Questions</p>	
            <p style="text-align:justify">Given the usage of a model and a specific edge device can it be deployed on edge device itself or will it has to be deployed on a cloud service in order to get the expcected prediction or output?</p>	
            <p style="text-align:justify;font-weight:bolder;font-size: 16px; margin-bottom:5px">Sub Research Questions</p>	
            <ul style="color:#3e3e3e; margin-bottom: 7px" >
              <li style="margin-bottom: 7px">How benchmarking works and what are the parameters tested by benchmark tests?</li>
              <li style="margin-bottom: 7px">What is indicated by the result of a benchmarks test regarding capability of mobile ?</li>
              <li style="margin-bottom: 7px">How the benchmarks tests can be compared with each other?</li>
              <li style="margin-bottom: 7px">How to use benchmarking in order to decide if a particular model can be deployed on a mobile or not? </li>
              <li style="margin-bottom: 7px">Can an existing neural network be optimized using optimizing techniques and convert to a mobile friendly architecture?</li>
              <li style="margin-bottom: 7px">Given the use case of a neural network what is the best way to optimize it  for the mobile environment?</li>
              <li style="margin-bottom: 7px">What are the available cloud services to deploy machine learning models and what are their capabilities, limitations, pros and cons?</li>
              <li style="margin-bottom: 7px">What is the best way to run deep learning model predictions in mobile app? </li>
            </ul>            
            <p style="text-align:justify;font-weight:bolder;font-size: 20px;margin-top:20px">Objective of the study</p>					
            <p style="text-align:justify">The major objective of this study is to build a mobile app capable of handling various machine learning algorithms optimized for the mobile environment in the best way according to the available resources of the device and network capabilities. </p>	
            <p style="text-align:justify;font-weight:bolder;font-size: 20px;">Mindmap of the Project</p>	 
            <br><br>
            <img
            style="height:700px; margin: auto; display: block "
            src="images/federated_mindmap.png"
            class="img-fluid"
            alt=""
            />
            <br><br>
            <ul class="work-detail-list">
							<li style="font-size: 14px"><span>Area of research :</span>Network Optimization and Acceleration, Mobile Computing, Distributed Computing, Machine Learning, Federated Learning</li>
							<li style="font-size: 14px"><span>Supervisor :</span>Dr. Nuwan Kodagoda (primary), Dr. Dharshana Kasthurirathna, Dr. Shyam Reyal, Dr. Pradeepa Samarasinghe</li>
							<li style="font-size: 14px"><span>Research Assistant :</span>Mr. Asiri Gawesha Lindamulage </li>
              <li style="font-size: 14px"><span>Contact :</span>asiri.l@sliit.lk</li>
						</ul>


            <br><br><br><br>
            <div id="graphNN-research-section"></div>
						<h3 style="color:#24478f; font-size: 23px; font-weight:bolder;" class="margin-bottom-15">Joint Attention Analysis</h3>	
						<p style="text-align:justify">The main analysis on the CSAAT project involves videos of children for early detection of the
autism spectrum disorder (ASD). Often, monitoring and quantifying the ability of children to interact with parents and professional therapists is essential in identifying any potential issues in their development growth. In this research, we plan to analyse the interactions between child and mother/examiner. This involves the use of image pre-processing techniques along with deep learning techniques such as graph neural networks to analyse the behaviours of the child as well as his/her interaction with others. The outcomes of this research may be useful in early identification and continuous monitoring of development goals and social interaction expectations of children.</p>					
						 
						<ul class="work-detail-list">
							<li style="font-size: 14px"><span>Area of research :</span>Deep Learning, Computer Vision</li>
							<li style="font-size: 14px"><span>Supervisor :</span>Dr. Pradeepa Samarasinghe (primary), Dr. Dharshana Kasthurirathna</li>
							<li style="font-size: 14px"><span>External Supervisor :</span>Dr. Charith Abhayaratne</li>
              <li style="font-size: 14px"><span>Research Assistant :</span>Mr. Sanka Mohottala </li>
              <li style="font-size: 14px"><span>Contact :</span>sanka.m@sliit.lk</li>
						</ul> 
            
              <!-- Adding a picture under  Sanka 's Research description, 
              change src with correct location, and remove the comment tags. -->

           
            <!--
            <br><br>
            <img
            style="height:400px; margin: auto; display: block "
            src="images/speech_rec_sys_diagram.png"
            class="img-fluid"
            alt=""
            />
            -->
                        
					</div>
                    <!--End Work Detail-->
				</div> <!--/ row-->
			</div> <!--/ container-->		
		</section>
		<!--End single-work -->


<script>
var coll = document.getElementsByClassName("collapsible");
var i;

for (i = 0; i < coll.length; i++) {
  coll[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var content = this.nextElementSibling;
    if (content.style.maxHeight){
      content.style.maxHeight = null;
    } else {
      content.style.maxHeight = content.scrollHeight + "px";
    } 
  });
}
</script>
    </section>

  </main><!-- End #main -->

   <!-- ======= Footer ======= -->
  <footer id="footer">

    <div class="container">
      <div class="copyright">
        &copy; Copyright <strong><span>CSAAT</span></strong>. All Rights Reserved
      </div>
      <div class="credits">
        <!-- All the links in the footer should remain intact. -->
        <!-- You can delete the links only if you purchased the pro version. -->
        <!-- Licensing information: https://bootstrapmade.com/license/ -->
        <!-- Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/scaffold-bootstrap-metro-style-template/ -->
        Designed by <a href="https://www.sliit.lk/">SLIIT</a>
      </div>
    </div>
  </footer><!-- End Footer -->

  <a href="#" class="back-to-top"><i class="bx bxs-up-arrow-alt"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/jquery/jquery.min.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/jquery.easing/jquery.easing.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/venobox/venobox.min.js"></script>
  <script src="assets/vendor/owl.carousel/owl.carousel.min.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
